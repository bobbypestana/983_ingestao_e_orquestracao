{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplos brokers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kafka-architecture](https://s3-sa-east-1.amazonaws.com/lcpi/032ec305-71c0-4b07-8f87-f56849c021c4.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar, inicie o servidor Zookeeper.\n",
    "\n",
    "---\n",
    "```bash\n",
    "$KAFKA_HOME/bin/zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties\n",
    "```\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para inicializar um cluster Kafka com $id=1,2,3,...,N$ brokers, é preciso executar o seguinte procedimento para cada servidor $id$. \n",
    "\n",
    "\n",
    "1. Crie uma cópia do arquivo de configuração padrão `server.properties`, que se encontra em `$KAFKA_HOME/config/`\n",
    "    ```bash\n",
    "        cp $KAFKA_HOME/config/server.properties $KAFKA_HOME/config/server-<id>.properties\n",
    "    ```\n",
    "2. Altere as seguintes configurações do arquivo criado: \n",
    "   ```bash\n",
    "       nano $KAFKA_HOME/config/server-<id>.properties\n",
    "    ```\n",
    "\n",
    "    ```nano\n",
    "        broker.id=<id>\n",
    "        listeners=PLAINTEXT://localhost:909<2+id> \n",
    "        log.dirs=/tmp/kafka-logs-<id>\n",
    "    ```\n",
    "\n",
    "3. Inicie o servidor\n",
    "```bash\n",
    "    $KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server-<id>.properties\n",
    "```\n",
    "\n",
    "Substitua `<id>` pelo ID do broker correspondente (0, 1, 2 etc). É importante que cada broker seja iniciado com seu próprio arquivo de configuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurando os tópicos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar alguns tópicos com diferentes características para em seguida explorar suas propriedades.\n",
    "\n",
    "---\n",
    "`topic_create`\n",
    "```python\n",
    "from kafka.admin import KafkaAdminClient, NewTopic\n",
    "\n",
    "# Configura os brokers\n",
    "bootstrap_servers = ['localhost:9092', 'localhost:9093', 'localhost:9094']\n",
    "\n",
    "# Cria o objeto KafkaAdminClient\n",
    "admin_client = KafkaAdminClient(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "# Cria a lista de tópicos\n",
    "topic_list = [NewTopic(name='topic_1', num_partitions=4, replication_factor=1),\n",
    "              NewTopic(name='topic_2', num_partitions=3, replication_factor=2),\n",
    "              NewTopic(name='topic_3', num_partitions=2, replication_factor=3)]\n",
    "\n",
    "\n",
    "# Cria os tópicos\n",
    "for topic in topic_list:\n",
    "    try:\n",
    "        admin_client.create_topics(new_topics=[topic], validate_only=False)\n",
    "        print(f'Topic {topic.name} created successfully.')\n",
    "        print('\\n')\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(f'Erro: {ex}')\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "# Encerra o objeto KafkaAdminClient\n",
    "admin_client.close()\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigando o servidor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entendermos a dinâmica do Kafka, iremos frequentemente olhar a descrição dos tópicos. No terminal, usamos o código\n",
    "\n",
    "---\n",
    "```bash\n",
    "$KAFKA_HOME/bin//kafka-topics.sh --describe  --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --topic topic_1\n",
    "```\n",
    "---\n",
    "\n",
    "onde o último argumento é opcional, ou seja, podemos removê-lo para ver as descrição de todos os tópicos existentes.\n",
    "\n",
    "![topic_describe](https://s3-sa-east-1.amazonaws.com/lcpi/813511b3-4d7e-4798-9428-8f205e75a5d5.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comando `kafka-topics --describe  --bootstrap-server <bootstrap_servers> --topic <topic_name>`  é usado para obter informações sobre as partições e replicação de um tópico específico em um cluster Kafka. O resultado deste comando fornece informações detalhadas sobre o tópico, como o número de partições, fator de replicação, líder da partição, replicas em sincronia (in-sync replicas, ISR), bem como algumas informações adicionais, como configurações do tópico e permissões.\n",
    "\n",
    "- **Topic**: O nome do tópico.\n",
    "\n",
    "- **PartitionCount**: O número de partições do tópico.\n",
    "\n",
    "- **ReplicationFactor**: O número de réplicas para cada partição. Importante para garantir que os dados não sejam perdidos se um ou mais brokers falharem.\n",
    "\n",
    "- **Configs**: As configurações do tópico, que podem incluir informações sobre compactação de dados, retenção de dados, tamanho máximo de mensagem, entre outros.\n",
    "\n",
    "- **Partition**: O número da partição.\n",
    "\n",
    "- **Leader**: O ID do broker líder para a partição, responsável por coordenar o processo de leitura e gravação na partição.\n",
    "\n",
    "- **Replicas**: O ID dos brokers que armazenam as réplicas da partição, que são cópias dos dados armazenados em vários brokers no cluster Kafka.\n",
    "\n",
    "- **Isr**: O ID dos brokers que armazenam as réplicas em sincronia (in-sync replicas, ISR) da partição, ou seja, são réplicas que estão atualizadas com o líder da partição e podem assumir a liderança caso o líder falhe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar e flexibilizar nossa interação com o servidor, podemos usar o script `08_topic_describe.py`, que reproduz parte dos resultados mostrados em linha de comando. Note que esse script pode ser expandido conforme sua necessidade.\n",
    "\n",
    "---\n",
    "`topic_describe`\n",
    "```python\n",
    "from kafka.admin import KafkaAdminClient\n",
    "\n",
    "# Cria uma instância do KafkaAdminClient\n",
    "admin_client = KafkaAdminClient(\n",
    "    bootstrap_servers=['localhost:9092', 'localhost:9093', 'localhost:9094'],\n",
    ")\n",
    "\n",
    "# Define o nome do tópico a ser descrito\n",
    "topic_names = admin_client.list_topics()\n",
    "topic_names = ['topic_1','topic_2','topic_3']\n",
    "\n",
    "# Descreve o tópico\n",
    "topic_description = admin_client.describe_topics(topic_names)\n",
    "\n",
    "\n",
    "print(f'{\"Tópico\":<9} {\"Partição\"} {\"Líder\"} {\"Réplicas\":<15} {\"In-Sync Replicas (isr)\":<10}  {\"offline_replicas\"} ')\n",
    "\n",
    "for topic in topic_description:\n",
    "    for partition in topic[\"partitions\"]:\n",
    "    \n",
    "        print(f'{topic[\"topic\"]:<12}  {partition[\"partition\"]:<5}  {partition[\"leader\"]:<5}  {partition[\"replicas\"] } {\"  \":10} {partition[\"isr\"] } {\"  \":20} {partition[\"offline_replicas\"] } ' )\n",
    "          \n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com frequência nos perguntamos quaL o estado de escrita e leitura em uma determinada partição. Conforme discutido anteriormente, essa é uma informação inerente ao consumidor e não ao servidor. O servidor `zookeeper` só armazena os metadados para referência!\n",
    "\n",
    "No terminal, podemos usar o comando\n",
    "\n",
    "---\n",
    "```bash\n",
    "$KAFKA_HOME/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --describe --group 1\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "que resulta em\n",
    "\n",
    "![group_offset](https://s3-sa-east-1.amazonaws.com/lcpi/ad2b997b-6ef2-453f-92b5-f4b5dc1b6252.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comando \"kafka-consumer-groups --bootstrap-server localhost:9092 --group my-group --describe\" retorna informações detalhadas sobre o grupo de consumidores \"my-group\" registrado no cluster Kafka com o broker na porta 9092. \n",
    "\n",
    "O resultado consiste em uma tabela com as seguintes colunas:\n",
    "\n",
    "- `GROUP`: nome do grupo de consumidores;\n",
    "\n",
    "- `TOPIC`: nome do tópico;\n",
    "\n",
    "- `PARTITION`: número da partição do tópico;\n",
    "\n",
    "- `CURRENT-OFFSET`: último offset consumido pelo grupo de consumidores;\n",
    "\n",
    "- `LOG-END-OFFSET`: próximo offset disponível no tópico e partição;\n",
    "\n",
    "- `LAG`: número de mensagens que ainda não foram consumidas pelo grupo de consumidores na partição;\n",
    "\n",
    "- `CONSUMER-ID`: ID do consumidor dentro do grupo;\n",
    "\n",
    "- `HOST`: endereço IP do host que executa o consumidor.\n",
    "\n",
    "O valor em LAG é especialmente útil para entender o quão \"atrasado\" está o grupo de consumidores em relação às mensagens mais recentes no tópico e pode ser utilizado para detectar possíveis gargalos ou problemas de desempenho no consumo de mensagens."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como no caso anterior, usaremos um script em python para facilitar nossa interação. O script `08_group_offset.py` pode ser ajustado para melhor atender suas necessidades e sua versão inicial é dada abaixo.\n",
    "\n",
    "---\n",
    "```python\n",
    "from kafka import KafkaConsumer, TopicPartition\n",
    "\n",
    "\n",
    "groups = ['1']\n",
    "\n",
    "for group_id_ in groups:\n",
    "\n",
    "    # Configurações do consumidor\n",
    "    consumer = KafkaConsumer(\n",
    "        bootstrap_servers=['localhost:9092', 'localhost:9093', 'localhost:9094'],\n",
    "        auto_offset_reset='earliest',\n",
    "        group_id=group_id_,\n",
    "        )\n",
    "\n",
    "    topics = ['topic_1', 'topic_2','topic_3']\n",
    "\n",
    "    # Define o tópico e a partição desejada\n",
    "    for topic in topics:\n",
    "        partitions = consumer.partitions_for_topic(topic)\n",
    "        \n",
    "        try:\n",
    "            for partition in partitions:\n",
    "\n",
    "            \n",
    "            \n",
    "                # Definir a partição que deseja consultar\n",
    "                tp = TopicPartition(topic, partition)\n",
    "\n",
    "                # Atribuir a partição ao consumidor\n",
    "                consumer.assign([tp])\n",
    "                \n",
    "                # Obter a posição atual do offset\n",
    "                current_offset = consumer.position(tp)\n",
    "            \n",
    "                # Obter o offset mais recente da partição\n",
    "                end_offset = consumer.end_offsets([tp])[tp]\n",
    "\n",
    "                # Calcular a diferença entre a posição atual e o offset mais recente\n",
    "                unconsumed_messages = end_offset - current_offset\n",
    "                \n",
    "                print(f'group_id: {group_id_} topic: {topic} partition: {partition:3} current_offset: {current_offset:5} end_offset: {end_offset:5} unconsumed_messages: {unconsumed_messages:5}')\n",
    "        except Exception as ex:\n",
    "            print(f'Erro: {ex}')\n",
    "    print('\\n')\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** Com múltiplos brokers, tópicos e partições, como decidir para onde enviar uma mensagem ou mesmo saber para onde ela foi enviada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método `send()` do `KafkaProducer` em Python retorna um objeto `Future` que representa o resultado da chamada assíncrona para enviar uma mensagem ao Kafka broker. Este objeto `Future` possui vários métodos que podem ser usados para interagir com o resultado da chamada, incluindo:\n",
    "\n",
    "- `get()`: Espera até que a mensagem seja enviada com sucesso (ou falhe) e retorna o resultado.\n",
    "\n",
    "- `add_callback(callback)`: Adiciona um callback a ser executado quando a mensagem for enviada com sucesso.\n",
    "\n",
    "- `add_errback(callback)`: Adiciona um callback a ser executado se ocorrer um erro ao enviar a mensagem.\n",
    "\n",
    "Aqui está um exemplo de como usar o método `send()` com o objeto `Future` retornado pelo método:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`producer`\n",
    "```python\n",
    "from kafka import KafkaProducer   # Importa a classe KafkaProducer da biblioteca kafka-python\n",
    "import datetime as dt   # Importa a biblioteca datetime para trabalhar com datas e horas\n",
    "import time   # Importa a biblioteca time para adicionar atrasos ao envio das mensagens\n",
    "import random\n",
    "\n",
    "# Configura os brokers\n",
    "bootstrap_servers = ['localhost:9092', 'localhost:9093', 'localhost:9094']\n",
    "\n",
    "# Cria o produtor\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    value_serializer=lambda x: x.encode('utf-8')\n",
    ")\n",
    "\n",
    "\n",
    "# Funções de callback\n",
    "def on_send_success(record_metadata):\n",
    "    print(f'Mensagem enviada com sucesso para o tópico {record_metadata.topic} na partição {record_metadata.partition} com offset {record_metadata.offset}')\n",
    "\n",
    "def on_send_error(ex):\n",
    "    print(f'Erro ao enviar mensagem: {ex}')\n",
    "\n",
    "# Lista de tópicos e partições\n",
    "topic_partitions = [\n",
    "    {'topic': 'topic_1', 'partitions': 4},\n",
    "    {'topic': 'topic_2', 'partitions': 3},\n",
    "    {'topic': 'topic_3', 'partitions': 2}\n",
    "]\n",
    "\n",
    "# Envia mensagens aleatoriamente para tópicos e partições\n",
    "while True:\n",
    "\n",
    "    # Escolhe o tópico\n",
    "    topic_partition = random.choice(topic_partitions)\n",
    "    topic = topic_partition['topic']\n",
    "\n",
    "    # Cria a mensagem\n",
    "    time_stamp = dt.datetime.strftime(dt.datetime.now(), format='%Y-%m-%d %H:%M:%S.%f') \n",
    "    value_ = f'{time_stamp} Essa mensagem é enviada por KafkaProducer.'\n",
    "\n",
    "    # Envia a mensagem para o Kafka\n",
    "    future = producer.send(topic, value=value_)\n",
    "\n",
    "    # Espera a confirmação da entrega\n",
    "    try:\n",
    "        record_metadata = future.get(timeout=10)\n",
    "        on_send_success(record_metadata)\n",
    "    except Exception as ex:\n",
    "        on_send_error(ex)\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "# Encerra o produtor\n",
    "producer.flush()\n",
    "producer.close()\n",
    "```\n",
    "---\n",
    "\n",
    "Observe que os callbacks são executados em outra thread, portanto, se você precisar de sincronia, é necessário aguardar a execução do callback ou usar algum mecanismo de sincronização, como uma fila ou uma variável de condição.\n",
    "\n",
    "\n",
    "A classe `RecordMetadata` do KafkaProducer retorna informações sobre a gravação de uma mensagem em um tópico, incluindo o tópico, a partição e o offset atribuídos à mensagem.\n",
    "\n",
    "\n",
    "- `topic`: o nome do tópico em que a mensagem foi gravada.\n",
    "\n",
    "- `partition`: o número da partição do tópico em que a mensagem foi gravada.\n",
    "\n",
    "- `offset`: o número do offset da mensagem na partição do tópico.\n",
    "\n",
    "- `serializedKeySize`: o tamanho da chave serializada da mensagem.\n",
    "\n",
    "- `serializedValueSize`: o tamanho do valor serializado da mensagem.\n",
    "\n",
    "- `timestamp`: o timestamp da mensagem, se o produtor definiu um timestamp.\n",
    "\n",
    "- `checksum`: o checksum da mensagem, se o tópico estiver configurado para usar verificação de integridade.\n",
    "\n",
    "- `serializedHeaderSize`: o tamanho total dos headers serializados da mensagem.\n",
    "\n",
    "Esses atributos podem ser úteis para monitorar o desempenho e a integridade do sistema e para depurar problemas de produção e consumo de mensagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo anterior, deixamos o Kafka decidir em qual partição gravar a mensagem, mas poderíamos decidir nos mesmo. Além disso, podemos definir uma chave única para cada mensagem, a fim de identificá-la quando necessário.\n",
    "\n",
    "Para isso, adicionamos as linhas a seguir no nosso produtor.\n",
    "\n",
    "---\n",
    "`producer`\n",
    "```python\n",
    "# Cria o produtor\n",
    "producer = KafkaProducer(\n",
    "    ...,\n",
    "    key_serializer=lambda x: x.encode('utf-8'),\n",
    ")\n",
    "\n",
    "\n",
    "# Envia mensagens aleatoriamente para tópicos e partições\n",
    "while True:\n",
    "    ...\n",
    "    partition_ = random.randint(0, topic_partition['partitions']-1)\n",
    "\n",
    "    # Cria a chave e valor da mensagem\n",
    "    key_ = f'{topic}-partition-{partition_}'\n",
    "    value_ = ...\n",
    "\n",
    "    # Envia a mensagem para o Kafka\n",
    "    future = producer.send(..., key=key_, partition=partition_)\n",
    "```\n",
    "---\n",
    "\n",
    "\n",
    "Podemos ainda verificar que o atributo `timestamp` se refere ao envio da mensagem e não à geração da mensagem.\n",
    "\n",
    "---\n",
    "`producer`\n",
    "```python\n",
    "# Funções de callback\n",
    "def on_send_success(record_metadata):\n",
    "    delivery_time = dt.datetime.fromtimestamp(record_metadata.timestamp / 1e3)\n",
    "    print(f'Mensagem enviada com sucesso em {delivery_time} para o tópico {record_metadata.topic} na partição {record_metadata.partition} com offset {record_metadata.offset}')\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "value_ = ...\n",
    "print(value_)\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** Temos três brokers, três tópicos e até quatro partições. Sabendo que cada mensagem é enviada para uma partição específica (de forma aleatória ou não), como passar ao consumidor o local exato para leitura?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entendermos o funcionamento do Kafka explorando seus tópicos, precisamos primeiramente ter um consumidor associado a um grupo. \n",
    "\n",
    "Em primeiro lugar, repare que o consumidor pode ler dos três brokers, mas indicamos apenas um tópico e uma partição!\n",
    "\n",
    "---\n",
    "`consumer`\n",
    "```python\n",
    "# Importa a classe KafkaConsumer da biblioteca kafka-python\n",
    "from kafka import KafkaConsumer, TopicPartition\n",
    "import time\n",
    "\n",
    "# Cria uma instância de um consumidor Kafka e configura o endereço do servidor de bootstrap e o nome do tópico a ser consumido\n",
    "consumer = KafkaConsumer(\n",
    "    bootstrap_servers=['localhost:9092', 'localhost:9093', 'localhost:9094'],\n",
    "    auto_offset_reset='earliest',\n",
    "    group_id='1'\n",
    ")\n",
    "\n",
    "# Atribuir a partição e o offset desejados\n",
    "tp = TopicPartition('topic_1', 0)  # partição 0 de 'my_topic'\n",
    "consumer.assign([tp])\n",
    "consumer.seek(tp, 0)  # move para o offset X\n",
    "\n",
    "current_offset = consumer.position(tp)\n",
    "end_offset = consumer.end_offsets([tp])[tp]\n",
    "\n",
    "print(f'current_offset: {current_offset} - end_offset: {end_offset}')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    current_offset = consumer.position(tp)\n",
    "    end_offset = consumer.end_offsets([tp])[tp]\n",
    "\n",
    "    print(f'current_offset: {current_offset} - end_offset: {end_offset}')\n",
    "\n",
    "    # Lê as mensagens do Kafka em lotes, com um limite de X mensagens por lote.\n",
    "    messages = consumer.poll(max_records=5, timeout_ms=3000)\n",
    "    \n",
    "    \n",
    "    # Itera pelos lotes de mensagens lidos.\n",
    "    for tp, msgs in messages.items():\n",
    "        print(f'------ Batch limit ------')\n",
    "\n",
    "        # Itera pelas mensagens de cada lote.\n",
    "        for msg in msgs:\n",
    "        \n",
    "            print(f\"Offset: {msg.offset}, Chave: {msg.key}, Valor: {msg.value.decode('utf-8')}\")\n",
    "\n",
    "            # commita o offset da última mensagem consumida para todas as partições atribuídas\n",
    "            consumer.commit()\n",
    "    \n",
    "    time.sleep(1)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alta disponibilidade\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crie os tópicos `topic_1`, `topic_2` e `topic_3` e assegure-se que estejam vazios.\n",
    "2. Inicie o produtor.\n",
    "3. Inicie o consumidor acima.\n",
    "4. Execute o arquivo `08_topic_offset.py` .\n",
    "\n",
    "**Pergunta:** Quais partições foram lidas? Você esperava esse resultado?\n",
    "\n",
    "5. Execute o arquivo `08_topic_describe.py`.\n",
    "6. Derrube um broker com `Ctrl+C` na respectiva janela.\n",
    "\n",
    "**Pergunta:** Produtor e consumidor continuam funcionando? \n",
    "\n",
    "7. Execute o arquivo `08_topic_describe.py` novamente.\n",
    "\n",
    "**Pergunta:** O que significam os valores nas colunas `In-Sync Replica` e `Offline Replicas`?\n",
    "\n",
    "\n",
    "8. Reinicie ese broker e repita o processo para os outros.\n",
    "9. Execute o arquivo `08_topic_describe.py` novamente.\n",
    "\n",
    "\n",
    "**Pergunta:**  Explique por que os valores de `In-Sync Replica` e `Offline Replicas` mudaram novamente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Múltiplos consumidores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Certifique-se que todos os brokers estejam ligados e sincronizados.\n",
    "\n",
    "**Pergunta:** Como verificar a última condição?\n",
    "\n",
    "2. Desligue o consumidor.\n",
    "3. Verifique os offsets de todos os tópicos e partições com o script `08_topic_offset.py`.\n",
    "4. Ajuste o consumidor com as configurações abaixo e ligue-o novamente.\n",
    "   - `group_id`=1\n",
    "   - `topic`=topic_1\n",
    "   - `partition`=0\n",
    "5.  Ajuste o consumidor com as configurações abaixo e ligue-o em um novo terminal.\n",
    "   - `group_id`=1\n",
    "   - `topic`=topic_3\n",
    "   - `partition`=1\n",
    "\n",
    "**Pergunta:** Quantas partições temos ao todo? Em quantas estamos escrevendo dados? Quantas estão sendo consumidas?\n",
    "\n",
    "6.  Ajuste o consumidor com as configurações abaixo e ligue-o em um novo terminal.\n",
    "   - `group_id`=2\n",
    "   - `topic`=topic_1\n",
    "   - `partition`=0\n",
    "  \n",
    "7. Ajuste o consumidor com as configurações abaixo e ligue-o em um novo terminal.\n",
    "   - `group_id`=2\n",
    "   - `topic`=topic_3\n",
    "   - `partition`=1\n",
    "\n",
    "**Pergunta:** Verifique se os consumidores paralelos (aqueles que leem da mesma partição) interferem nas leituras uns dos outros.\n",
    "\n",
    "**Pergunta:** Como descobrir o offset atual de cada consumidor?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encerrando os servidores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$KAFKA_HOME/bin/kafka-server-stop.sh $KAFKA_HOME/config/server.properties\n",
    "\n",
    "$KAFKA_HOME/bin/zookeeper-server-stop.sh $KAFKA_HOME/config/zookeeper.properties"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
